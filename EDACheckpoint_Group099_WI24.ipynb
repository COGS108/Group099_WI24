{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Nicole Kim\n",
    "- Rikako Ono\n",
    "- Geena Limfat\n",
    "- MyungJoo Kim\n",
    "- Elizaveta Beltyukova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does higher usage of public transportation in a county affect the number of car crashes in that county? \n",
    "\n",
    "Additionally, does higher use of public transportation lessen the severity of the car accident?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Over the years, advancements in car safety, including structural design improvements and technological developments, have enhanced vehicle safety.\n",
    "Despite these progressions, the frequency of car accidents has increased significantly in recent years.\n",
    "In the United States alone, there were 6,102,936 police-reported vehicle accidents in 2021<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2).\n",
    "Various factors contribute to car crashes in the US, such as distracted driving, speeding, drunk driving, reckless driving, and tailgating.\n",
    "Notably, more than a third (36%) of all fatal crashes involve alcohol<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2).\n",
    "\n",
    "These behaviors collectively contribute to the high rate of car accidents in the US, underlining the importance of addressing these issues through awareness campaigns, preventive measures, and effective policies to enhance road safety.\n",
    "\n",
    "Public transportation serves as a vital component of urban areas by offering consistent transportation services through modes like buses, streetcars, light rail, ferries, and subways.\n",
    "This mode of transportation is essential for diverse groups such as older adults, individuals with disabilities, and commuters, particularly in major cities where public transit is prevalent. \n",
    "Public transportation not only provides a means of travel but also contributes to health and equity in various ways.\n",
    "Research indicates that public transportation can reduce traffic accidents and air pollution while increasing physical activity and improving access to essential services like medical care, healthy food, employment opportunities, and social connections.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). \n",
    "Despite these benefits, it remains unexplored whether the utilization of public transportation correlates with the severity of car crashes in an area.\n",
    "\n",
    "To investigate the relationship between public transport usage and the number and severity of car crashes in an area, one could explore how increased public transportation utilization might lead to reduced traffic congestion and fewer private vehicles on the road. \n",
    "However, it’s also possible that less traffic congestion could encourage drivers to travel at higher speeds, thus being more likely to cause a more severe/fatal accident in the area.\n",
    "Another factor to consider is that with increased public transport use, there could be more pedestrians, and therefore potentially more car-caused pedestrian injuries or deaths. \n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) [Evaluating Public Transportation Health Benefits. (n.d.).](https://www.vtpi.org/tran_health.pdf) \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) [Moore, T. (2024, January 16). Fatal car crash statistics 2024. USA Today.](https://www.usatoday.com/money/blueprint/auto-insurance/fatal-car-crash-statistics/#:~:text=There%20are%20nearly%2043%2C000%20fatal,accidents%20in%20the%20United%20States.&text=Of%20those%2C%2039%2C508%20were%20fatal) \n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) [Top 25 causes of car accidents: Exploring the major factors. GJEL Accident Attorneys. (2023, November 24).](https://www.gjel.com/car-accident-lawyers/top-causes-car-accidents ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Alternate Hypothesis: We hypothesize that higher use of public transportation lessens the number of accidents due to several factors. One of the factors being that public transportation involves professional drivers who go through rigorous training to operate the mode of transportation that they are in charge of and may adhere more strictly to traffic regulations and safety protocols which can reduce the likelihood of accidents. Therefore, they will be better experienced and equipped to handle situations that may cause accidents. Additionally, a higher usage of public transportation will result in fewer vehicles on the road which can reduce congestion and lower the probability of accidents. Thus, we hypothesize that a higher utilization of public transportation could contribute to a safer transportation environment and reduce the number of accidents on the road. In addition to this, we believe that higher use of public transportation will also lessen the severity of car accidents that occur. A higher use of public transportation indicates that there will be fewer vehicles on the road which can potentially reduce the number of reckless drivers on the road as well. Fewer reckless drivers on the road can lessen the severity of accidents. Since there are also less cars on the road, there would be less cars to crash into each other and create a 'domino effect' and involve other vehicles, thus involving less people and potentially lessening the overall severity of the entire crash. Additionally, public transportation drivers are better equipped to handle accidents as they have more training so they can better react to the situation and potentially lesssen the severity of the crash.\n",
    "\n",
    "Null Hypothesis: The use of public transportation does not affect the number of car crashes. It also does not affect the severity of the accident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "- Dataset #1\n",
    "  - Dataset Name: US Accidents (2016 - 2023)\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents?select=US_Accidents_March23.csv\n",
    "  - Number of observations: 7,728,394\n",
    "  - Number of variables: 46\n",
    "- Dataset #2\n",
    "  - Dataset Name: Highest Public Transit Usage Cities in California\n",
    "  - Link to the dataset: https://www.homearea.com/rankings/place-in-ca/percent_using_public_transportation/#:~:text=The%20California%20percent%20using%20public,year%20saw%20several%20big%20changes\n",
    "  - Number of observations: 62\n",
    "  - Number of variables: 3\n",
    "\n",
    "The first dataset refers to the US accident, encompassing 7,728,394 observations recorded between 2016 and 2023.\n",
    "The main features in this dataset include  the name of City, start time, description of the accident, and severity.\n",
    "The second dataset focuses  on public transportation usage in California, specifically in 62 cities in CA. This dataset comprises exactly 62 observations, each corresponding to a different city.\n",
    "\n",
    "We propose combining the subset of the first dataset, focusing only on the region of California in 2017, with the second dataset to address the impact of public transportation on the car accident rate in California and other potential factors.\n",
    "This combined dataset allows a comprehensive analysis of the relationship between public transportation use, and various factors influencing car accidents in California.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Dataset #1\n",
    "\n",
    "This dataset is somewhat clean. The dataset is consistent and uniform throughout. There is a small issue with completeness, as there is some missing data. \n",
    "The dataset's description states, “There is missing data for certain days, which could be due to network connectivity issues during data collection.” \n",
    "However, for the values that do remain, we are confident that they are accurate and reliable. \n",
    "In the description, it states “The data was collected from APIs broadcast traffic data captured by various entities, including the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road networks.” \n",
    "Because APIs have low latency, real-time data processing, and quick response times, we can conclude that the data is precise. \n",
    "We can also conclude from this excerpt that the sources are credible and trustworthy.\n",
    "\n",
    "In terms of pre-processing, we will clean the data by removing any missing inputs. \n",
    "We will attempt to make the file smaller so that it can be cleaned and uploaded to GitHub. \n",
    "We have confirmed that the dataset included at least a year’s worth of data to observe trends for appropriate time frames. \n",
    "We also checked that the source was reliable. \n",
    "\n",
    "To make our data usable, we first converted the ‘Start_Time’ column into a datetime object, so that we can filter the crash data by year (2017). Within the to_datetime function, we specified errors = ‘coerce’ to better handle improper formatted or mixed date strings in the dataframe. Then, we filtered the state to just be California, and the year to just be 2017 (using dt.year). Then, we selected the columns ‘Start_Time’, ‘Severity’, ‘City’, and ‘Description’, and sorted the dataframe by Start_Time, while also resetting the index.  \n",
    " \n",
    "\n",
    "\n",
    "### Dataset #2\n",
    "\n",
    "This dataset is very clean. This is mainly because we created our own data set. Thus, we had full control over what variables, observations, and units of measurement were included.\n",
    "We had full control of the quality of the data set. We made sure all the data was consistent and complete.\n",
    "We ensured the credibility of the data, by making sure it was taken from a reputable source like the U.S. Census Bureau American Community Survey.\n",
    "Unfortunately, the data may have small holes in precision, as survey participation is often voluntary.\n",
    "However, the source states that certain cities “were ranked the previous year but did not have sufficient data or population for the most recent rankings.”\n",
    "From this we can conclude that the source has only published results that had solid data to support it, thus making the research conducted accurate.\n",
    "\n",
    "In terms of pre-processing, we cleaned the data as we entered it into our dataset. We checked that it included at least a year’s worth of data to observe trends for appropriate time frames.\n",
    "We checked that it was consistent with our other data set. We checked that it was a trustworthy source.\n",
    "\n",
    "To get the data into a usable format we had to take research and statistics from various websites related to our study.\n",
    "We then had to transform the file type twice. First, we inputted data into an Excel spreadsheet for ease of viewing and editing.\n",
    "Second, we converted the file into a CSV to be read by pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1 - US Accidents (2016 - 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the original dataset was too large to be uploaded on GitHub, we cleaned the data locally with the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('US_Accidents_March23.csv')\n",
    "\n",
    "# create a subset of the dataset with relevant year 2017, which we will be using for the rest of the project\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "\n",
    "accidents_df = df[df['State'] == 'CA'][df['Start_Time'].dt.year == 2017]\n",
    "accidents_df = accidents_df.get(['Start_Time', 'Severity', 'City', 'Description']).sort_values(by='Start_Time').reset_index(drop=True)\n",
    "\n",
    "accidents_df.to_csv(r\"~\\AccidentData.csv\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>Severity</th>\n",
       "      <th>City</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:03:31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Norwalk</td>\n",
       "      <td>Accident on I-5 Northbound at Exits 120 120A B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 00:09:26</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Lynwood</td>\n",
       "      <td>Accident on I-710 Southbound at Exits 12 12A 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 00:09:52</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Hesperia</td>\n",
       "      <td>Accident on I-15 Northbound at Exit 138 Oak Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 00:10:14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>Accident on CA-110 Southbound at Glenarm St.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 00:11:14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Colton</td>\n",
       "      <td>Accident on I-10 Eastbound at Exit 72 I-215.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Start_Time  Severity      City  \\\n",
       "0  2017-01-01 00:03:31      0.75   Norwalk   \n",
       "1  2017-01-01 00:09:26      0.75   Lynwood   \n",
       "2  2017-01-01 00:09:52      0.75  Hesperia   \n",
       "3  2017-01-01 00:10:14      0.50  Pasadena   \n",
       "4  2017-01-01 00:11:14      0.75    Colton   \n",
       "\n",
       "                                         Description  \n",
       "0  Accident on I-5 Northbound at Exits 120 120A B...  \n",
       "1  Accident on I-710 Southbound at Exits 12 12A 1...  \n",
       "2  Accident on I-15 Northbound at Exit 138 Oak Hi...  \n",
       "3       Accident on CA-110 Southbound at Glenarm St.  \n",
       "4       Accident on I-10 Eastbound at Exit 72 I-215.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accident_df = pd.read_csv('AccidentData.csv')\n",
    "\n",
    "# normalize severity to be on a scale of 0-1 instead of 1-4 to make comparing easier later on\n",
    "accident_df['Severity'] = accident_df['Severity']/4\n",
    "\n",
    "accident_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 - Highest Public Transit Usage Cities in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Percent Using Transit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oakland</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daly City</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Lakewood</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>San Buenaventura (Ventura)</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Irvine</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Visalia</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Napa</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          City  Percent Using Transit\n",
       "0                San Francisco                  0.347\n",
       "1                      Oakland                  0.227\n",
       "2                     Berkeley                  0.221\n",
       "3                    Daly City                  0.207\n",
       "4                      Alameda                  0.185\n",
       "..                         ...                    ...\n",
       "57                    Lakewood                  0.008\n",
       "58  San Buenaventura (Ventura)                  0.008\n",
       "59                      Irvine                  0.008\n",
       "60                     Visalia                  0.006\n",
       "61                        Napa                  0.005\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "City = ['San Francisco', 'Oakland', 'Berkeley', 'Daly City', 'Alameda', 'San Leandro', 'Richmond', 'Pleasanton', 'San Mateo', 'Concord', 'San Ramon', 'Hayward', 'Los Angeles', 'Mountain View', 'Fremont', 'Antioch', 'Sunnyvale', 'Pittsburg', 'East Los Angeles', 'Redwood City', 'Vallejo', 'Pasadena', 'Long Beach', 'El Cajon', 'San Jose', 'Santa Clara', 'Santa Ana', 'Inglewood', 'South Gate', 'San Diego', 'Downey', 'Sacramento', 'Chula Vista', 'Santa Clarita', 'Glendale', 'Anaheim', 'Escondido', 'Riverside', 'Santa Rosa', 'Oceanside', 'Santa Barbara', 'Elk Grove', 'Palmdale', 'San Bernardino', 'Fullerton', 'Fresno', 'Moreno Valley', 'Pomona', 'Huntington Beach', 'Santa Maria', 'Lancaster', 'Ontario', 'Garden Grove', 'Corona', 'Bakersfield', 'Stockton', 'Rancho Cucamonga', 'Lakewood', 'San Buenaventura (Ventura)', 'Irvine', 'Visalia', 'Napa']\n",
    "Percent_Used = [0.347, 0.227, 0.221, 0.207, 0.185, 0.149, 0.121, 0.105, 0.103, 0.099, 0.098, 0.098, 0.089, 0.088, 0.081, 0.079, 0.076, 0.071, 0.066, 0.066, 0.061, 0.055, 0.055, 0.053, 0.05, 0.049, 0.048, 0.047, 0.046, 0.04, 0.038, 0.038, 0.036, 0.034, 0.033, 0.031, 0.03, 0.03, 0.026, 0.023, 0.023, 0.021, 0.021, 0.021, 0.021, 0.02, 0.019, 0.018, 0.018, 0.018, 0.016, 0.015, 0.014, 0.012, 0.011, 0.011, 0.011, 0.008, 0.008, 0.008, 0.006, 0.005]\n",
    "\n",
    "transit_df = pd.DataFrame({'City':City, 'Percent Using Transit':Percent_Used})\n",
    "\n",
    "transit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rikak\\AppData\\Local\\Temp\\ipykernel_20500\\2025032227.py:3: FutureWarning: The provided callable <function mean at 0x000002A3CAEC5080> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  accident_df_new = accident_df.groupby('City').agg(avg_severity=('Severity', np.mean), num_accidents=('Description', np.count_nonzero)).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>avg_severity</th>\n",
       "      <th>num_accidents</th>\n",
       "      <th>Percent Using Transit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anaheim</td>\n",
       "      <td>0.546612</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antioch</td>\n",
       "      <td>0.514423</td>\n",
       "      <td>208</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>0.534253</td>\n",
       "      <td>562</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>0.694248</td>\n",
       "      <td>565</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chula Vista</td>\n",
       "      <td>0.662577</td>\n",
       "      <td>326</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Concord</td>\n",
       "      <td>0.540720</td>\n",
       "      <td>528</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Corona</td>\n",
       "      <td>0.576827</td>\n",
       "      <td>1793</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Daly City</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>278</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Downey</td>\n",
       "      <td>0.696450</td>\n",
       "      <td>845</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City  avg_severity  num_accidents  Percent Using Transit\n",
       "0      Alameda      0.500000              6                  0.185\n",
       "1      Anaheim      0.546612           2022                  0.031\n",
       "2      Antioch      0.514423            208                  0.079\n",
       "3  Bakersfield      0.534253            562                  0.011\n",
       "4     Berkeley      0.694248            565                  0.221\n",
       "5  Chula Vista      0.662577            326                  0.036\n",
       "6      Concord      0.540720            528                  0.099\n",
       "7       Corona      0.576827           1793                  0.012\n",
       "8    Daly City      0.640288            278                  0.207\n",
       "9       Downey      0.696450            845                  0.038"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To better compare the datasets, we will merge them by city name.\n",
    "\n",
    "accident_df_new = accident_df.groupby('City').agg(avg_severity=('Severity', np.mean), num_accidents=('Description', np.count_nonzero)).reset_index()\n",
    "accidents_vs_transit = pd.merge(accident_df_new, transit_df, on='City')\n",
    "accidents_vs_transit.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #3 - Population per City in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table with row headers in column A and column headers in rows 3 through 4 (leading dots indicate sub-parts)</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Annual Estimates of the Resident Population fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geographic Area</td>\n",
       "      <td>2010-04-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Population Estimate (as of July 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Census</td>\n",
       "      <td>Estimates Base</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelanto city, California</td>\n",
       "      <td>31765</td>\n",
       "      <td>31760</td>\n",
       "      <td>31661</td>\n",
       "      <td>31864.0</td>\n",
       "      <td>31088.0</td>\n",
       "      <td>31206.0</td>\n",
       "      <td>32522.0</td>\n",
       "      <td>32961.0</td>\n",
       "      <td>33249.0</td>\n",
       "      <td>33952.0</td>\n",
       "      <td>34070.0</td>\n",
       "      <td>34049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agoura Hills city, California</td>\n",
       "      <td>20330</td>\n",
       "      <td>20336</td>\n",
       "      <td>20338</td>\n",
       "      <td>20475.0</td>\n",
       "      <td>20544.0</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>20648.0</td>\n",
       "      <td>20740.0</td>\n",
       "      <td>20665.0</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>20411.0</td>\n",
       "      <td>20222.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  table with row headers in column A and column headers in rows 3 through 4 (leading dots indicate sub-parts)  \\\n",
       "0  Annual Estimates of the Resident Population fo...                                                            \n",
       "1                                    Geographic Area                                                            \n",
       "2                                                NaN                                                            \n",
       "3                          Adelanto city, California                                                            \n",
       "4                      Agoura Hills city, California                                                            \n",
       "\n",
       "            Unnamed: 1      Unnamed: 2                          Unnamed: 3  \\\n",
       "0                  NaN             NaN                                 NaN   \n",
       "1  2010-04-01 00:00:00             NaN  Population Estimate (as of July 1)   \n",
       "2               Census  Estimates Base                                2010   \n",
       "3                31765           31760                               31661   \n",
       "4                20330           20336                               20338   \n",
       "\n",
       "   Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2      2011.0      2012.0      2013.0      2014.0      2015.0      2016.0   \n",
       "3     31864.0     31088.0     31206.0     32522.0     32961.0     33249.0   \n",
       "4     20475.0     20544.0     20591.0     20648.0     20740.0     20665.0   \n",
       "\n",
       "   Unnamed: 10  Unnamed: 11  Unnamed: 12  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2       2017.0       2018.0       2019.0  \n",
       "3      33952.0      34070.0      34049.0  \n",
       "4      20572.0      20411.0      20222.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_df = pd.read_excel('SUB-IP-EST2019-ANNRES-06.xlsx')\n",
    "\n",
    "population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rikak\\AppData\\Local\\Temp\\ipykernel_20500\\786506040.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  col_values[0] = population_df.iloc[1][0]\n",
      "C:\\Users\\rikak\\AppData\\Local\\Temp\\ipykernel_20500\\786506040.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col_values[0] = population_df.iloc[1][0]\n",
      "C:\\Users\\rikak\\AppData\\Local\\Temp\\ipykernel_20500\\786506040.py:5: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  col_values[0] = population_df.iloc[1][0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>City</th>\n",
       "      <th>Population in 2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelanto</td>\n",
       "      <td>33952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agoura Hills</td>\n",
       "      <td>20572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>79037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany</td>\n",
       "      <td>20076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alhambra</td>\n",
       "      <td>84878.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "2          City  Population in 2017\n",
       "0      Adelanto             33952.0\n",
       "1  Agoura Hills             20572.0\n",
       "2       Alameda             79037.0\n",
       "3        Albany             20076.0\n",
       "4      Alhambra             84878.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The code does not have proper column markers, and has excess information. We will fix that with the following:\n",
    "\n",
    "# Fix column values\n",
    "col_values = population_df.iloc[2]\n",
    "col_values[0] = population_df.iloc[1][0]\n",
    "population_df.columns = col_values\n",
    "\n",
    "# Simplify rows and columns\n",
    "population_df = population_df[3:]\n",
    "population_df = population_df.reset_index(drop=True).get(['Geographic Area', 2017.0]).rename(columns={'Geographic Area': 'City', 2017.0:'Population in 2017'})\n",
    "population_df['City'] = population_df['City'].str.title().str.replace(', California', '').str.replace(' City', '')\n",
    "population_df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>num_accidents</th>\n",
       "      <th>Population in 2017</th>\n",
       "      <th>accident_rate</th>\n",
       "      <th>avg_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>6</td>\n",
       "      <td>79037.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anaheim</td>\n",
       "      <td>2022</td>\n",
       "      <td>350476.0</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.546612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antioch</td>\n",
       "      <td>208</td>\n",
       "      <td>111494.0</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.514423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>562</td>\n",
       "      <td>377940.0</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.534253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>565</td>\n",
       "      <td>122164.0</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.694248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chula Vista</td>\n",
       "      <td>326</td>\n",
       "      <td>269046.0</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.662577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Concord</td>\n",
       "      <td>528</td>\n",
       "      <td>129592.0</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.540720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Corona</td>\n",
       "      <td>1793</td>\n",
       "      <td>167310.0</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>0.576827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Downey</td>\n",
       "      <td>845</td>\n",
       "      <td>112426.0</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.696450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>El Cajon</td>\n",
       "      <td>371</td>\n",
       "      <td>103468.0</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.602426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City  num_accidents  Population in 2017  accident_rate  avg_severity\n",
       "0      Alameda              6             79037.0       0.000076      0.500000\n",
       "1      Anaheim           2022            350476.0       0.005769      0.546612\n",
       "2      Antioch            208            111494.0       0.001866      0.514423\n",
       "3  Bakersfield            562            377940.0       0.001487      0.534253\n",
       "4     Berkeley            565            122164.0       0.004625      0.694248\n",
       "5  Chula Vista            326            269046.0       0.001212      0.662577\n",
       "6      Concord            528            129592.0       0.004074      0.540720\n",
       "7       Corona           1793            167310.0       0.010717      0.576827\n",
       "8       Downey            845            112426.0       0.007516      0.696450\n",
       "9     El Cajon            371            103468.0       0.003586      0.602426"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will merge this into the dataset 'accidents_vs_transit' to get the per-capita accident rate of each city.\n",
    "\n",
    "clean_df = pd.merge(accidents_vs_transit, population_df, on='City')\n",
    "clean_df = clean_df.assign(accident_rate = clean_df['num_accidents']/clean_df['Population in 2017'])\n",
    "\n",
    "clean_df = clean_df.get(['City', 'num_accidents', 'Population in 2017', 'accident_rate', 'avg_severity'])\n",
    "\n",
    "# Look at some values in our cleaned dataframe\n",
    "clean_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through cleaning the data, it can be observed that the length of our dataset shortened to 58 observations. This is due to some of the values not being in the other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Carry out whatever EDA you need to for your project.  Because every project will be different we can't really give you much of a template at this point. But please make sure you describe the what and why in text here as well as providing interpretation of results and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 of EDA - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 of EDA if you need it  - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should not be an issue with any biases from the source of collection as the dataset that we are exmaining the data from takes the data from multiple APIs which broadcast traffic data which is captured from various sources, including the US and state departments of transportation, law enforcement agencies, trafic cameras, and trafic sensors within road network. This should allow us to avoid any biases as there are many sources of information that went into this dataset which can validate each other. Additionally, as some of the data is taken in from traffic cameras and sensors, the data is inputted by a machine/algorithm which will remove human biases.\n",
    "\n",
    "However, there may be biases in which accidents were reported to the government as there may be racial/ethical biases when it came to reporting the accidents to the government.\n",
    "This may exclude certain demographics of people or target others, but as we are not focusing on race/demographics, it should not affect our data analysis as much. Additionally, since the data is vastly spread across the country and over the time frame of 2016 - 2013, the data should even out itself.\n",
    "\n",
    "One factor we may fail to fully consider is the location and its impact on each accident.\n",
    "For example, there may be weather conditions or other variables that we are unable to record that may be the main reason for the accident, yet we concluded a different reasoning with the information we analyzed.\n",
    "However, this should still be acceptable as the main goal of our hypothesis and research is to find out how certain factors consistently result in an accident.\n",
    "In other words, our focus is more on concluding if there will be an accident if a certain variable is present, rather than which variable is the most crucial out of all variables to lead to an accident.\n",
    "\n",
    "\n",
    "We will detect these specific biases before analysis by thoroughly discussing our research question before finding datasets and identifying any additional variables that would skew our data and affect our question.\n",
    "During data analysis, we will identify any points in the data that do not match up with the rest of the data and conduct additional research to identify whether those specific data points are abnormalities or whether they are biases that we did not take into account before.\n",
    "Then, we will explain the abnormalities/biases in our analysis and discuss how this affects our data.\n",
    "After we have already written our analysis of the data, we will proofread our conclusion for any other biases that may stand out and if they do occur, we will revise and address them again.\n",
    "Additionally, we may conduct a peer review (if allowed) with another group so we can have unbiased feedback.\n",
    "\n",
    "We will not be avoiding anyone's privacy when collecting data about the public transportation usage rates as the rates are generalized to the entire city and should not be exposing any indivdual person's privacy. To avoid violating anyone's privacy who was involved in the accident, we may remove/recode any information that can identify the individual(s) involved in the accident. This includes any distinguishing features about the vehicles involved in the accident. \n",
    "\n",
    "Our question will not bring up any ethical concerns as it does not dive into the demographics of any of the people involved in the study. It only takes into account the public rates of public transportation usage and car accident data. Our question will not have any ethical implications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* *Keep in touch with group members via iMessage or Discord groupchat.*\n",
    "* *Encourage open communication about progress, challenges, and any assistance needed to complete tasks on time.*\n",
    "* *Fill out When2Meet's on time in order to coordinate meeting times.*\n",
    "* *Be open to adjusting timelines, strategies, or goals as needed to ensure the project's success*\n",
    "* *Complete individually assigned tasks on time and hold each team member accountable for their assigned tasks and deadlines*\n",
    "* *Define each team member's role and responsibilities within the project. Make sure everyone understands what is expected of them and how their contributions fit into the overall project goals.*\n",
    "* *Set clear deadlines for project deliverables and milestones*\n",
    "* *Break down the project into manageable tasks with specific timelines to track progress and ensure that the project stays on schedule*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/3  |  12 PM | Determind best form of communication  | Complete Previous Project Review Assignment | \n",
    "| 2/7  |  6:30PM |  Brainstorm ideas for project | Work on Project Proposal Assignment | \n",
    "| 2/12 | 8:30 PM |  Brainstorm any new ideas for project + potential datasets | Finish Project Proposal Assignment|\n",
    "| 2/17  | 12 PM | Find Data and work on Research. Review Feedback and brainstorm any additional changes | Start on Checkpoint #1: Data   |\n",
    "| 2/22  | 3 PM | Attend office hours for more project insight | Discuss what to add/change to the project. Assign roles to different sections |\n",
    "| 2/22 - 2/25  | between meetings | Work on individually assigned parts of the Checkpoint. Communicate with team members any changes or issues | On your own work |\n",
    "| 2/25  | 6:30 PM  | Import & Wrangle Data. Individual tasks. | Discuss any findings and update group on project made. Complete Checkpoint #1: Data   |\n",
    "| 3/2 | 12 PM  | Review any feedback and brainstorm appropriate changes in response. | Start on Checkpoint #2: EDA |\n",
    "| 3/2 - 3/19 | between meetings  | Work on assigned roles. Update team members on any changes or issues. | On your own work|\n",
    "| 3/10 | 6:30 PM  | Complete analysis; Draft results/conclusion/discussion | Confirm and finalize what changes should be made. Complete Checkpoint #2: EDA  |\n",
    "| 3/15 | 12 PM  | Work on assigned Tasks | Work together to discuss and wrap up the Final Project |\n",
    "| 3/20  | Before 11:59 PM  | Make final edits and prepare to turn in Final Project | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
